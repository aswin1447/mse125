{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Week 4 Discussion: MLE and method of moments"], "execution_count": 0, "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": ["*Originally by Jongbin Jung, Camelia Simoiu, Jerry Lin.*\n", "*Minor edits from Alex Chohlas-Wood*"], "execution_count": 0, "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": ["![that-moment-when](img/that_moment_when.jpg)\\\n", "*(cue bad \"moment\" pun groans)*"], "execution_count": 0, "outputs": []}, {"cell_type": "code", "execution_count": 0, "metadata": {"collapsed": true, "jupyter": {"outputs_hidden": true}}, "outputs": [], "source": ["set.seed(125)\n", "knitr::opts_chunk$set(echo = TRUE)\n", "options(repr.plot.width=4, repr.plot.height=3)\n", "library(\"dplyr\")\n", "library('ggplot2')\n", "theme_set(theme_bw())\n", "comma <- function(n) {\n", "  format(n, big.mark = \",\")\n", "}\n", "theta <- 20\n", "n <- 5\n", "example_times <- round(runif(n, 0, theta));"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Introduction\n", "\n", "### Let's imagine...\n", "\n", "... during a long vacation to some foreign country, you\u2019ve been taking the same bus every morning. "], "execution_count": 0, "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": ["![that-moment-when](img/bus.jpg)"], "execution_count": 0, "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": ["Since you\u2019re on vacation, the \u201cmorning\u201d has been starting at pretty random times for you, but you\u2019ve been told that the buses in this country try to arrive in constant intervals throughout the whole day.\n", "\n", "During your stay so far, the times you\u2019ve waited for a bus (in minutes) have been:\n", "\n", "    16,2,6,7,19\n", "\n", "We wish to know the constant interval at which buses are supposed to arrive."], "execution_count": 0, "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": ["### A model\n", "\n", "Let\u2019s call this interval $\\theta$.\n", "\n", "One way to model the historically observed wait times, $X_1,X_2,\\cdots,X_5$, is to treat them as independent and identially distributed draws from a Uniform(0, $\\theta$) distribution. This does require, however, that you\u2019re willing to make at least two assumptions:\n", "\n", "1. your arrival time at bus stops in the mornings has been pretty random \n", "1. the bus you take does indeed arrive every $\\theta$ minutes.\n", "\n", "While not everyone might be on board with these assumptions, let\u2019s just agree to take them as given, for the purpose of illustration.$^1$\n", "\n", "Similar to [last week\u2019s example](https://mybinder.org/v2/gh/stanford-policylab/mse125/HEAD?filepath=week_2%2Festimators-answers.ipynb), there are a few natural and intuitive estimators for $\\theta$, given the observed data. But this week, we want to take a more principled approach in finding estimators, so that we have a few ways to construct estimators in situations where obvious/intuitive ones aren\u2019t available. The two methods we look at are [**method of moments**](#Method-of-moments-estimator) and [**maximum likelihood estimators**](#Maximum-likelihood-estimator)."], "execution_count": 0, "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": ["## Method of moments estimator\n", "\n", "If we assume that our observed wait times $X_i$ follow a Uniform(0, $\\theta$) distribution, then we know from the properties of a Uniform distribution, that the first moment of $X_i$ given the fixed parameter $\\theta$, i.e, \n", "\n", "$$ a_1(\\theta) = \\mathbb{E}_\\theta(X_i)=  \\frac{\\theta}{2}.$$ "], "execution_count": 0, "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": ["But remember, this is a theoretical value, and not something we can compute from the observed data. With the data, we can estimate the $j$-th moment of $X_i$ via:\n", "\n", "$$ \\hat{a}_j = \\frac{1}{n}\\sum_{i=1}^n(X_i)^j$$"], "execution_count": 0, "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": ["or for the first moment, simply the sample mean:\n", "\n", "$$\\hat{a}_1 = \\bar{X}_n = \\frac{1}{n} \\sum_{i=1}^n(X_i).$$"], "execution_count": 0, "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": ["Given both the theoretical and estimated moments, one way to estimate the parameter $\\theta$\n", "would be to set it such that our estimated moment is exactly the theoretical moment$^2$. In other words, we wish to set our estimator $\\tilde{\\theta}$ such that:\n", "\n", "$$\n", "\\begin{align}\n", "a_1(\\tilde{\\theta}) &= \\hat{a}_1 \\\\\n", "\\frac{\\tilde{\\theta}}{2} &= \\bar{X}_n \\\\ \n", "\\tilde{\\theta} &= 2 \\cdot \\bar{X}_n.\n", "\\end{align}\n", "$$"], "execution_count": 0, "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": ["In the case of our example, we would compute:\n", "\n", "$$2 \\cdot \\bigg( \\frac{16+2+6+7+19}{5} \\bigg) = 20.$$"], "execution_count": 0, "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": ["## Maximum likelihood estimator\n", "\n", "Another way to construct an estimator is to start from the joint distribution of the observed data, $f(x_1,x_2,\\cdots,x_n;\\theta)$. In the case of $X_i \u223c \\textrm{Uniform}(0,\\theta)$, we have\n", "\n", "$$\n", "f(x_i;\\theta) = \n", "\\begin{cases}\n", "\\frac{1}{\\theta} & \\text{if}~x_i \\le \\theta \\\\\n", "0 & \\text{otherwise}\n", "\\end{cases}\n", "$$"], "execution_count": 0, "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": ["and, since $X_i$ are all independent, \n", "\n", "$$\n", "f(x_1,x_2,\\cdots,x_n;\\theta) = \n", "\\begin{cases}\n", "(\\frac{1}{\\theta})^n & \\text{if}~x_i \\le \\theta~\\forall_i \\\\\n", "0 & \\text{otherwise}\n", "\\end{cases}\n", "$$"], "execution_count": 0, "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": ["Recall that in this joint density, the parameter $\\theta$ is fixed, and $f$ is a function of the observable data $X_1,\\cdots,X_n.$ \n", "But in reality, we\u2019ve observed draws of each $X_i$, and would like to know how likely our observed data would have been under different values of $\\theta$. \n", "We can represent this likelihood by thinking of the joint density of the data given $\u03b8$ as a function of $\u03b8$, where the data $X_i$ are now fixed to the values we\u2019ve observed:\n", "\n", "$$\n", "\\mathcal{L}_n(\\theta) =\n", "\\begin{cases}\n", "(\\frac{1}{\\theta})^n & \\text{if}~x_i \\le \\theta~\\forall_i \\\\\n", "0 & \\text{otherwise}\n", "\\end{cases}\n", "$$"], "execution_count": 0, "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": ["Then, one estimate of $\\theta$ might be to find the value of $\\theta$ that makes this likelihood as big as possible, a.k.a., the **maximum likelihood estimator**.\n", "\n", "One common technique for finding the value of a parameter that maximizes the likelihood function is to take the log of the likelihood, often referred to as the log-likelihood. In this case, that would be:\n", "\n", "$$\n", "\\ell_n(\\theta) = \\log\\mathcal{L}_n(\\theta) =\n", "\\begin{cases}\n", "  -n\\log(\\theta) & \\text{if}~x_i \\le \\theta~\\forall_i \\\\\n", "  -\\infty & \\mathrm{otherwise}\n", "\\end{cases}\n", "$$"], "execution_count": 0, "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": ["To find the value of $\\theta$ that maximizes $\\ell(\\theta)$, we make two observations:\n", "\n", "1. $\\theta$ cannot be smaller than any of the observed values$^3$, otherwise $\\ell(\\theta)$ would be $-\\infty$!\n", "1. $-n\\log(\\theta)$ is a [monotonically decreasing function](https://en.wikipedia.org/wiki/Monotonic_function) of $\\theta$; \n", "which means we want to have the smallest possible value of $\\theta$, in order to maximize the value of $\\ell(\\theta)$."], "execution_count": 0, "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": ["Given these observations, the natural value $\\hat{\\theta}$ that maximizes\n", "$\\ell(\\theta)$ can be found to be $\\max(X_1, X_2, \\cdots, X_n)$,\n", "or in our case, $\\hat{\\theta} = \\max(16,2,6,7,19) = 19$.\n", "\n", "We can also use `R` to visualize the log-likelihood\n", "function $\\ell(\\theta)$ (and its maximum)\n", "as a function of $\\theta$, given our observed data.\n", "First, we implement $\\ell(\\theta)$ as a function in `R`:$^4$"], "execution_count": 0, "outputs": []}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["loglikelihood <- function(theta, X) {\n", "  n <- length(X)\n", "  cond <- max(X) <= theta\n", "  ifelse(cond, 1 / theta, -Inf)\n", "}"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Then, for the purpose of plotting, we create a data frame with a range of possible values for $\\theta$ and the corresponding likelihood:"], "execution_count": 0, "outputs": []}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["likelihood_df <- tibble(theta = 10:40) %>%\n", "  mutate(l = loglikelihood(theta, X = example_times)) %>%\n", "  filter(l != -Inf)\n", "ggplot(likelihood_df, aes(x = theta, y = l)) +\n", "  geom_vline(xintercept = example_times, linetype = \"dashed\") +\n", "  geom_line() +\n", "  geom_point(data = function(d) top_n(d, 1, l), size = 2) +\n", "  scale_x_continuous(expression(theta)) +\n", "  scale_y_continuous(\"Log-likelihood\\n\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["If the two estimators we find look familiar, that's because they are the estimates we present in [assignment #2](https://5harad.com/mse125/#hw2)."], "execution_count": 0, "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": ["![we-made-it](img/we_made_it.jpg)"], "execution_count": 0, "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": ["## Exercise \n", "\n", "Now that we've seen how to find both MLE and method of moments estimators,\n", "let's practice with a different distribution.\n", "\n", "A sample of 3 independent observations ($X_1 = 0.4$, $X_2 = 0.7$, $X_3 = 0.9$)\n", "is collected from a continuous distribution with density function:\n", "\n", "$$\n", "f(x;\\theta) = \\theta x^{\\theta\u22121}, \\text{where } 0 < x < 1.\n", "$$\n", "We would like to estimate the unknown parameter $\\theta$.\n", "\n", "Let's use the two methods we've covered above to find estimators of $\\theta$."], "execution_count": 0, "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": ["### Method of moments estimator \n", "#### Overview\n", "\n", "Recall that the method of moments involves:\n", "\n", "1. Analytically finding the theoretical moments of the data\n", "1. Computing the observed moments of the data\n", "1. Setting the estimator such that the observed moments are equal to the \n", "   theoretical moments\n", "   \n", "Finding estimators for $j$ unknown parameters would require $j$ equations, and \n", "hence we would need to find up to the $j^{\\mathrm{th}}$ moment.\n", "For this exercise, since we have just one unknown parameter $\\theta$, \n", "we only need to find one equation involving the first moment."], "execution_count": 0, "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": ["#### Theoretical moment\n", "\n", "Let's start by deriving the first theoretical moment $m_1(\\theta)$ (the mean)! Express $m_1(\\theta)$ in terms of $\\theta$.\\\n", "*Your solution here! HINT: A reminder that for this continuous distribution,* $\\mathbb{E}_\\theta[X_i] = \\int_0^{1} x f(x) dx$.\n", "\n"], "execution_count": 0, "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": ["#### Observed moment\n", "\n", "Now, use the plugin estimator for the first sample moment $\\hat{m}_1$:\\\n", "*Your solution here!*\n", "\n"], "execution_count": 0, "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": ["#### Estimator\n", "\n", "Finally, we find our estimator, let's call it $\\tilde{\\theta}$, to be the \n", "value of $\\theta$ such that the observed moment is equal to the analytical\n", "moment:\n", "\n", "$$\n", "m_1(\\tilde{\\theta}) = \\hat{m}_1\n", "$$"], "execution_count": 0, "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": ["Plug in what you found above and solve for $\\tilde{\\theta}$ to get your estimator:\\\n", "*Your solution here!*\n", "\n"], "execution_count": 0, "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": ["Now, let's estimate $\\tilde{\\theta}$ from our data! Plug our sampled values into your estimator.\\\n", "*Your solution here!*\n", "\n"], "execution_count": 0, "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": ["### Maximum likelihood estimator \n", "\n", "#### Overview\n", "\n", "As we have done in the above example, an MLE can be found in two steps:\n", "\n", "1. Find the log-likelihood as a function of $\\theta$, starting from the joint\n", "   distribution of the data, $f(X_1, X_2, \\ldots, X_n; \\theta)$.\n", "1. Given the observed data, find the value of $\\theta$ that maximizes\n", "   the likelihood. That's your estimate, $\\tilde{\\theta}$!"], "execution_count": 0, "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": ["#### Finding the log-likelihood\n", "\n", "Remember that the density function is $f(x;\\theta) = \\theta x^{\\theta\u22121}$, and use the fact \n", "that the observed $X_i$ are independent, to write the joint density function:\\\n", "*Your solution here!*\n", "\n"], "execution_count": 0, "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": ["Then, re-write the joint density function as a likelihood function of $\\theta$ given our observed data $(X_1, X_2, X_3)$:\\\n", "*Your solution here!*\n", "\n"], "execution_count": 0, "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": ["Because the above expression involves taking products, we first find the \n", "log-likelihood $\\ell(\\theta) = \\log\\mathcal{L}(\\theta)$, which is easier \n", "to maximize.\n", "Note that, because the taking the log is a monotonic transformation, \n", "the value of $\\theta$ that maximizes $\\mathcal{L}(\\theta)$ is the same as the\n", "value of $\\theta$ that maximizes $\\ell(\\theta)$.\\\n", "*Your solution here! HINT: Can you transform the log of a product into a simpler expression?*\n", "\n"], "execution_count": 0, "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": ["#### Maximizing\n", "\n", "Finally, to find our estimator, we wish to maximize the log-likelihood derived above. To find the value of $\\theta$ that maximizes $\\ell(\\theta)$, \n", "take the derivative of $\\ell(\\theta)$ with respect to $\\theta$:\\\n", "*Your solution here! HINT: You can assume $log()$ refers to the natural log, i.e., $ln()$ or $log_{e}()$.*\n", "\n"], "execution_count": 0, "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": ["Then, our MLE $\\hat{\\theta}$ is the value at which the derivative of \n", "$\\ell(\\theta)$ is zero.$^5$\n", "That is, we wish to find the value $\\hat{\\theta}$ that satisfies setting our answer above equal to zero. Solving for $\\hat{\\theta}$, what do you find?\\\n", "*Your solution here!*\n", "\n"], "execution_count": 0, "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": ["Finally, let's plug-in the specific values of $X_i$ that we observe to calculate $\\hat{\\theta}$:\\\n", "*Your solution here! HINT: Remember, our estimator relied on us using the natural log for $log()$.*\n", "\n"], "execution_count": 0, "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": ["#### Visualization\n", "\n", "We can also visually confirm we have found the maximum value by plotting the\n", "value of $\\ell(\\theta)$ around the value of $\\hat{\\theta}$ that we have found.\n", "\n", "We first define the log-likelihood function:"], "execution_count": 0, "outputs": []}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["X <- c(.4, .7, .9)  # This is the data we have\n", "loglikelihood <- function(theta, X) {\n", "  3*log(theta) + (theta - 1) * sum(log(X))\n", "}"]}, {"cell_type": "markdown", "metadata": {}, "source": ["and then plot the value for a sequence of value surrounding the estimated value \n", "$\\hat{\\theta}$:"], "execution_count": 0, "outputs": []}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["theta_hat <- -3/sum(log(X))\n", "likelihood_df <- tibble( \n", "    theta = seq(theta_hat - 1, theta_hat + 1, 0.05) \n", "  ) %>% \n", "  mutate(l = loglikelihood(theta, X))\n", "ggplot(likelihood_df, aes(x = theta, y = l)) +\n", "  geom_line() +\n", "  geom_vline(xintercept = theta_hat, linetype = \"dashed\") +\n", "  scale_x_continuous(expression(theta)) +\n", "  scale_y_continuous(\"Log-likelihood\\n\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["![top-cat](img/made-it.png)"], "execution_count": 0, "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": ["## Footnotes\n", "\n", "1. While it\u2019s quite difficult to come up with real-life examples that fall exactly into some theoretical distribution, in practice, models based on such simplified assumptions provide surprisingly useful results.\n", "\n", "1. Note that in this case, we only have one unknown, $\\theta$, so solving one equation is sufficient; hence we only need to look at the first moment. In cases where there are more than one unknown parameter, we would have to compare the theoretical and estimated values of higher moments as well. More specifically, if we wanted to know both the lower and upper bounds of the Uniform distribution (instead of just assuming the lower bound to be 0), we would need at least the first and second moments of $X_i$.\n", "\n", "1. In our example, if $\\theta$ were actually smaller than the largest time we actually waited, this would imply that we had an unlucky day during which the bus was more delayed than usual. However, in theory (and under the assumptions of our model), we assume this doesn\u2019t happen.\n", "\n", "1. A proper implementation of the (log-)likelihood (as far as the math is concerned) would actually be a [closure](https://en.wikipedia.org/wiki/Closure_(computer_programming)) that takes the data ($X$) and returns the log-likelihood as a function of the parameter ($\\theta$); but to keep things simple here we\u2019re just going to create a function of both the parameter and data, and trust the user (us!) to be smart enough to keep the data constant.\n", "\n", "1. This is a bit sloppy. In reality, we would also have to check the second derivative of $\\ell(\\theta)$ to make sure that the $\\hat{\\theta}$  we find is indeed a maximum."], "execution_count": 0, "outputs": []}], "metadata": {"kernelspec": {"display_name": "R", "language": "R", "name": "ir"}, "language_info": {"codemirror_mode": "r", "file_extension": ".r", "mimetype": "text/x-r-source", "name": "R", "pygments_lexer": "r", "version": "3.6.3"}}, "nbformat": 4, "nbformat_minor": 4}