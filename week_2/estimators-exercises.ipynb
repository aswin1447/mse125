{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Week 2 Discussion: Estimators"], "execution_count": 0, "outputs": []}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["# Ensures consistent results from our simulations\n", "set.seed(125)\n", "\n", "# Load in tidyverse packages\n", "library(tidyverse)\n", "\n", "# Make our `ggplot` plots use a same black and white theme\n", "theme_set(theme_bw())"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Setup\n", "\n", "You're given a huge jar of Skittles and M&M's, mixed together (yuck!).\n", "\n", "![skittles](img/mm_skittles.jpg)\n", "\n", "You randomly pick 10 pieces of candy from the jar, and end up with 4 Skittles \n", "and 6 M&M's.\n", "\n", "**What proportion of the jar do you think are M&M's?**\n", "\n", "A natural, intuitive, **estimate** for the proportion of M&M's in the jar would be\n", "\n", "$$\\frac{6}{4 + 6} = 0.6$$\n", "\n", "But what can we say about this number? \n", "How certain are we that if we count _all_ the candy in the jar, the proportion\n", "of M&M's will be close to 60%?\n", "\n", "To answer these questions, we have to think more carefully about how that\n", "**0.6** came about, and what it means."], "execution_count": 0, "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": ["## Estimator\n", "\n", "Let's say there are $C$ pieces of candy in the jar and $M$ pieces are\n", "M&M's (i.e., there are $C-M$ Skittles in the jar). We'll call the actual\n", "proportion of M&M's in the jar $p$, which is exactly $M/C$. \n", "\n", "Then, taking out one candy from the jar and inspecting whether it's an M&M or\n", "Skittle is equivalent to a Bernoulli trial with probability $p$ of \"success\".\n", "We can also do this multiple times, and each time would be an independent \n", "Bernoulli trial, as long as we put the candy back in the jar every time.\n", "\n", "For each piece of candy that we inspect, let's write a 1 if it's an M&M and a \n", "0 if it's a Skittle, and we'll call the $i^\\textrm{th}$ number we write $X_i$.\n", "Then we can say that the **0.6** above comes from using the following **estimator**:\n", "\n", "$$\\hat{p} = \\frac{1}{N}\\sum_{i = 1}^{N}X_i$$\n", "\n", "with our observed data ($X_1, X_2, \\cdots X_{10}$), where $N$ is the number of\n", "pieces of candy we get to count.\n", "\n", "\n", "Now, to answer questions regarding our (un)certainty about that **0.6**\n", "number, we need to figure out the **distribution** of our estimator,\n", "$\\hat{p}$."], "execution_count": 0, "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": ["## Interlude: Distributions in `R`\n", "\n", "As you've seen in introductory probability, it's common to \n", "represent natural phenomena in terms of known probability distributions.\n", "For example, in a particular population, the height of individuals may\n", "be normally distribution with a mean $\\mu$ of 5.5 feet and a standard\n", "deviation $\\sigma$ of 0.5 feet. \n", "\n", "You can work with known distributions (e.g., Normal, Poisson, and\n", "Binomial) in `R` using the following notation:\n", "`<d,p,q,r><distribution_name>`\n", "\n", "For example, `dnorm`, `pbinom`, `qpoisson`, and `rbeta` are valid `R` commands. \n", "\n", "What do the four letters stand for?\n", "\n", "* d: density (i.e., the height of the distribution at a particular `x` value)\n", "* p: probability (i.e., the area under the distribution from $-\\infty$ to `x`)\n", "* q: quantile (i.e., the `x` value corresponding to a particular `p` [`p` is the area under the distribution from $-\\infty$ to `x`])\n", "* r: random (i.e., generate `n` random draws of `x` values from the distribution)\n", "\n", "### Examples\n", "\n", "Generate 10 random draws from the standard normal distribution."], "execution_count": 0, "outputs": []}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["# Equivalently, rnorm(10)\n", "rnorm(n = 10, mean = 0, sd = 1)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["What is the area under the standard normal distribution\n", "from 1 standard deviation below the mean to 2 standard deviations\n", "above the mean?"], "execution_count": 0, "outputs": []}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["# Equivalently, pnorm(2) - pnorm(-1)\n", "pnorm(q = 2, mean = 0, sd = 1) - pnorm(q = -1, mean = 0, sd = 1)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Exercises\n", "\n", "> **Simulate a carnival game where I have 10 guesses to win a prize, and, \n", "for each guess, the probability of winning a prize is 20%. \n", "You can win multiple prizes. Run your code several times. What was\n", "the minimum number of times you won? The maximum?**"], "execution_count": 0, "outputs": []}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["# Your code here! \n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["> **What value corresponds to the 97.5th percentile of the standard normal distribution?**"], "execution_count": 0, "outputs": []}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["# Your code here! \n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Distribution of an estimator \n", "\n", "### A simulation\n", "\n", "Before diving into distributions with more notation, symbols, and all that, \n", "let's think more carefully about what \"**the distribution of** $\\hat{p}$\" \n", "actually means. For this, we'll pretend we know exactly how many M&M's and \n", "Skittles are in the jar, and see what happens when we compute values of $\\hat{p}$.\n", "\n", "First, let's create that jar:"], "execution_count": 0, "outputs": []}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["M <- 1000   # Let's say this is the number of  M&M's\n", "S <- 2000   # and this is the number of Skittles.\n", "C <- M + S  # Then this is the total \n", "print(C)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["and the actual proportion of M&M's ($p$) is simply:"], "execution_count": 0, "outputs": []}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["p <- M/C\n", "print(p)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Then, randomly inspecting 10 pieces of candy from the jar is equivalent to 10 Bernoulli trials with probability $p$ of success, i.e.,"], "execution_count": 0, "outputs": []}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["N <- 10  # This is how many we get to count\n", "counted_candies <- rbinom(N, 1, p)\n", "print(counted_candies)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Remember, drawing an M&M is considered a \"success\" in this setting, so we can compute our estimator $\\hat{p}$ with"], "execution_count": 0, "outputs": []}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["p_hat <- sum(counted_candies)/N\n", "print(p_hat)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["The mean of a vector of 0s and 1s is the proportion of elements in the vector that are 1, so we can also do this:"], "execution_count": 0, "outputs": []}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["p_hat <- mean(counted_candies)\n", "print(p_hat)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["But that $\\hat{p}$ is just a number! How do we find its distribution? What does a distribution for $\\hat{p}$ even mean?!"], "execution_count": 0, "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": ["### Sampling distributions\n", "\n", "The distribution of an estimator (also commonly known as the sampling\n", "distribution) refers to how the values of $\\hat{p}$ would look like\n", "**if we were to repeat the counting for a whole bunch of samples (of the same size)**.\n", "\n", "In other words, if there were multiple parallel universes,\n", "what would the proportion of M&M's in each\n", "of those samples of 10 candies look like across all the universes?\n", "\n", "While it might be a little difficult to create a bunch of parallel universes in\n", "practice, this can easily be done in `R`:"], "execution_count": 0, "outputs": []}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["B <- 100  # Number of parallel universes to create\n", "multiverse_p_hats <- replicate(B, mean(rbinom(N, 1, p)))\n", "print(multiverse_p_hats)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### Exercise\n", "> **Now that we have `B` values of $\\hat{p}$ from `B` parallel universes,\n", "> make a histogram of the $\\hat{p}$ values. You may want to use\n", "> the `tibble` function to create a dataframe, and you may want to \n", "> adjust the default `binwidth` parameter of \n", "> `geom_histogram`.**"], "execution_count": 0, "outputs": []}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["# Your code here!\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### Properties of sampling distributions\n", "\n", "While we know the true value of $p$ (because we created it out of thin air!), we see that the value of $\\hat{p}$ varies across all `B` universes. \n", "\n", "However, the _average_ of $\\hat{p}$ (the estimated expected value of $\\hat{p}$) across all those universes is actually not that far from $p$."], "execution_count": 0, "outputs": []}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["p # actual value of p\n", "mean(multiverse_p_hats)  # Estimated expected value of p_hat\n", "mean(multiverse_p_hats) - p  # => quite small!"]}, {"cell_type": "markdown", "metadata": {}, "source": ["This difference between the actual value of interest ($p$) and the expected \n", "value of an estimator (average across multiple universes) is what's known as\n", "the **bias of an estimator**:\n", "\n", "$$\\mathbb{E}_p(\\hat{p}) - p$$\n", "\n", "We can also estimate the standard deviation of our estimator $\\hat{p}$ across\n", "multiple universes (often called the estimated **standard error**):"], "execution_count": 0, "outputs": []}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["sd(multiverse_p_hats)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### The math\n", "\n", "\n", "We can also compute the properties of our estimator $\\hat{p}$ analytically,\n", "without simulation (which is the kind of analysis we expect for Problem 1a and 1b of \n", "[homework 2](https://5harad.com/mse125/#hw2)).\n", "\n", "First, we have to start with basic probability.\n", "Remember, what we observe is $X_i$, and each of these $X_i$ all follow\n", "(independently and identically) a Bernoulli distribution with probability of\n", "success $p$. Then, from the [properties of a Bernoulli\n", "distribution](https://en.wikipedia.org/wiki/Bernoulli_distribution) we know that\n", "\n", "\\begin{align*}\n", "\\mathbb{E}_p(X_i) & = p \\\\\n", "\\mathrm{Var}_p(X_i) & = p(1-p) \\\\\n", "\\end{align*}\n", "\n", "where the subscript $_p$ in \n", "$\\mathbb{E}_p$ and $\\mathrm{Var}_p$ simply means that the actual value $p$ is fixed (i.e., it's _not_ random).\n", "\n", "**Linearity of expectation** implies the following:\n", "\n", "$$\\mathbb{E} \\left( \\sum_{i=1}^n X_i \\right) = \\sum_{i=1}^n \\mathbb{E}(X_i)$$\n", "Recall our estimator:\n", "\n", "$$\\hat{p} = \\frac{1}{N}\\sum_{i = 1}^{N}X_i$$"], "execution_count": 0, "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": ["#### Exercise \n", "\n", "> **Using the facts above, derive an expression for $\\mathbb{E}_p(\\hat{p})$.**"], "execution_count": 0, "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": ["Click here to write your answer in $\\LaTeX$, or write your answer on a separate sheet of paper."], "execution_count": 0, "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": ["\n", "<!-- \\begin{align*}\n", "\\mathbb{E}_p(\\hat{p}) & = \\mathbb{E}_p\\left(\\frac{1}{N}\\sum_{i = 1}^{N}X_i\\right) \\\\\n", "  & = \\frac{1}{N}\\mathbb{E}_p\\left(\\sum_{i = 1}^{N}X_i\\right) \\\\\n", "  & = \\frac{1}{N}\\sum_{i = 1}^{N}\\mathbb{E}_p(X_i) \\\\\n", "  & = \\frac{1}{N}\\sum_{i = 1}^{N}p \\\\\n", "  & = \\frac{1}{N}Np \\\\\n", "  & = p\n", "\\end{align*} -->"], "execution_count": 0, "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": ["#### Bias\n", "\n", "For the bias, we want to figure out the value of\n", "\n", "$$\\mathbb{E}_p(\\hat{p}) - p$$\n", "\n", "$\\mathbb{E}_p(\\hat{p}) - p = 0$, so we'd call $\\hat{p}$ **unbiased**. \n", "\n", "This is confirmed in our simulation above, where we find that the average of our $\\hat{p}$ estimates across `B` multiverses is very close to the true value of $p$!"], "execution_count": 0, "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": ["#### Standard error\n", "\n", "Again, what's known as the **standard error** is simply the **standard deviation of the sampling distribution**, where the _sampling distribution_ is the distribution of values that our estimator $\\hat{p}$ would take across multiple parallel universes.\n", "\n", "In other words, we want to know\n", "\n", "$$\\sqrt{\\mathrm{Var}_p(\\hat{p})}$$\n", "\n", "In case it's not clear yet, $\\hat{p}$ is a **random variable** that can take multiple values, depending on the exact samples ($X_i$) we happened to get, and $p$ is a real, fixed value (the proportion of M&M's in the jar) that won't change no matter how many candies we sample (unless we eat them)."], "execution_count": 0, "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": ["### Exercise\n", "\n", "> **Using the facts stated at the beginning of this section,\n", "> derive an expression for $\\mathrm{Var}_p(\\hat{p})$.**"], "execution_count": 0, "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": ["Click here to write your answer in $\\LaTeX$, or write your answer on a separate sheet of paper."], "execution_count": 0, "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": ["\n", "<!-- \\begin{align*}\n", "\\mathrm{Var}_p(\\hat{p})\n", "  & = \\mathrm{Var}_p\\left(\\frac{1}{N}\\sum_{i = 1}^{N}X_i\\right) \\\\\n", "  & = \\frac{1}{N^2}\\sum_{i = 1}^{N}\\mathrm{Var}_p(X_i) \\\\\n", "  & = \\frac{1}{N^2}Np(1-p) \\\\\n", "  & = \\frac{p(1-p)}{N}\n", "\\end{align*}\n", "\n", "and the standard error is:\n", "\n", "$$\\sqrt{\\mathrm{Var}_p(\\hat{p})} = \\sqrt{\\frac{p(1-p)}{N}}$$ -->"], "execution_count": 0, "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": ["We can confirm our result with the standard deviation of our estimates \n", "across multiverses, i.e.,"], "execution_count": 0, "outputs": []}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["# This is what the theory predicts we'll see\n", "sqrt(p*(1-p)/N) \n", "# This is what we get from parallel universes\n", "sd(multiverse_p_hats)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["But note that in reality, we couldn't really compute the theoretical standard error, since it requires knowing the value of $p$, which in this case, we know _only because we created it out of thin air_. \n", "\n", "So, in reality, we'd _estimate_ the standard error, by using our estimated value of $\\hat{p}$, in place of the true value $p$. For example, in this case we'd compute\n", "\n", "$$\\hat{\\mathrm{se}} =  \\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{N}}$$"], "execution_count": 0, "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": ["### Exercise\n", "\n", "> **Calculate $\\hat{\\mathrm{se}}$ for the very first example of 6 M&M's in a sample of 10 candies.**"], "execution_count": 0, "outputs": []}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["# Your code here!\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Confidence intervals \n", "\n", "Now we have some understanding of the distribution of our estimator.\n", "Given this information, what more can we say about our estimate, $\\hat{p} = 0.6$?\n", "Well, since we now know that there is some uncertainty associated with it, and we have some measure of that uncertainty (the estimated standard error), we can express our uncertainty in terms of a range of values, instead of trying\n", "to pin-point an exact value that we know won't be quite right.\n", "One way to do this is to construct a **confidence interval**.\n", "\n", "One simple yet common approximation for a confidence interval is to assume that the sampling distribution is close to a normal distribution, and start from there.\n", "\n", "As discussed in lecture, a $1-\\alpha$ confidence interval for our estimator $\\hat{p}$ can be constructed as:\n", "\n", "\\begin{align*}\n", "\\mathrm{CI} \n", "  & = \\left(\\hat{p} - z_{1 - \\alpha/2}\\mathrm{se}(\\hat{p}), \n", "      \\hat{p} + z_{1 - \\alpha/2}\\mathrm{se}(\\hat{p})\\right) \\\\\n", "  & \\approx \\left(\\hat{p} - z_{1 - \\alpha/2}\\hat{\\mathrm{se}}(\\hat{p}), \n", "      \\hat{p} + z_{1 - \\alpha/2}\\hat{\\mathrm{se}}(\\hat{p})\\right) \\\\\n", "  & = \\left(\\hat{p} - z_{1 - \\alpha/2}\\sqrt{\\hat{p}(1-\\hat{p})/N},  \n", "             \\hat{p} + z_{1 - \\alpha/2}\\sqrt{\\hat{p}(1-\\hat{p})/N}\\right)\n", "\\end{align*}\n", "\n", "where $z_{1 - \\alpha/2}$ is the value at which the CDF of a standard normal distribution is equal $1 - \\alpha/2$.\n", "\n", "![distribution](img/alpha-normal-distr.png)"], "execution_count": 0, "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": ["### Exercise\n", "\n", "> **Construct a 95% confidence interval for our initial estimate of $\\hat{p} = 0.6$. Note that we drew 10 candies to calculate this estimate.**"], "execution_count": 0, "outputs": []}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["# Your code here!\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Validation via simulation\n", "\n", "But what does this confidence interval mean?\n", "Well, to continue our multiverse analogy, a 95% confidence interval would mean that if we were to follow the exact same procedure in all of our parallel universes, **the true value of $p$ would be contained within the computed interval in about 95% of the universes.**\n", "\n", "This can be a little confusing, so let's try to clarify with some more simulation.\n", "Remember, in our parallel universe example, we actually _know_ the true value of  $p$, so we can check whether any interval created in any of the universes successfully contains that value or not. \n", "For convenience, let's start by creating a function that carries out our process of computing confidence intervals from a set of observations:"], "execution_count": 0, "outputs": []}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["# X: the vector of observed M&Ms (1s) and Skittles (0s)\n", "compute_ci <- function(X, alpha = 1 - .95) {\n", "  N <- length(X)\n", "  p_hat <- mean(X)\n", "  se <- sqrt(p_hat * (1 - p_hat) / N)\n", "  \n", "  c(p_hat - qnorm(1 - alpha/2)*se, \n", "    p_hat + qnorm(1 - alpha/2)*se)\n", "}"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Let's also write a function that, given a confidence interval and a true value, returns `TRUE` if the true value is contained in the interval, and `FALSE` otherwise:"], "execution_count": 0, "outputs": []}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["in_interval <- function(ci, p) {\n", "  # This works, but can be improved\n", "  # (e.g., we assume ci is sorted)\n", "  if (ci[1] <= p & ci[2] >= p) {\n", "    return(TRUE)\n", "  }\n", "  return(FALSE)\n", "}"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Now, we are ready to replicate parallel universes, \n", "generate confidence intervals, and see whether they contain the true value."], "execution_count": 0, "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": ["### Exercise\n", "\n", "> **Code up a simulation that generates confidence intervals for 100 universes, and calculates the proportion of universes for which the confidence interval contains the true value of $p$.**"], "execution_count": 0, "outputs": []}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["# Your code here!\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Exercise\n", "\n", "> **Ideally, the above simulation result should be close to `0.95`---because we constructed 95% confidence intervals; but it probably isn't. Why do you think this happened? What could you change above in that last block to make the simulation result closer to `0.95`?**\n", "\n", "> **(Hint: Think about the histogram from our previous simulation. Based\n", "on the shape of the histogram, are any assumptions violated?)**"], "execution_count": 0, "outputs": []}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["# Your answer/code here!\n", "\n"]}], "metadata": {"kernelspec": {"display_name": "R", "language": "R", "name": "ir"}, "language_info": {"codemirror_mode": "r", "file_extension": ".r", "mimetype": "text/x-r-source", "name": "R", "pygments_lexer": "r", "version": "3.6.3"}}, "nbformat": 4, "nbformat_minor": 4}